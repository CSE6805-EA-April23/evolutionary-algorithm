{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nur-E-Anika/evolutionary-algorithm/blob/main/HO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt-8eVeu2026",
        "outputId": "2ceabe5b-13d5-43f5-940a-610f086b9c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnnyNrHuywgq",
        "outputId": "e299d080-1149-4fb0-aa1a-41f1d465a69e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatasets) (4.66.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (from opendatasets) (1.5.16)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from opendatasets) (8.1.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.31.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (2.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle->opendatasets) (6.0.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle->opendatasets) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle->opendatasets) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets\n",
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGU7-d-J52Ux"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import pandas\n",
        "\n",
        "od.download(\"https://www.kaggle.com/competitions/titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZAMU2fU6ipI"
      },
      "outputs": [],
      "source": [
        "# !pip install numpy==1.24.4\n",
        "# !pip install pandas --upgrade\n",
        "# !pip install matplotlib --upgrade\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn --upgrade\n",
        "!pip install sklearn --upgrade"
      ],
      "metadata": {
        "id": "1axHCv4t7uwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tPjiFCO6WmA"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIXDK5nw8thp"
      },
      "outputs": [],
      "source": [
        "# load dataset using pandas\n",
        "titanic_train_df = pd.read_csv('./titanic/train.csv')\n",
        "titanic_test_df = pd.read_csv('./titanic/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VDxi6DL9Ipn"
      },
      "outputs": [],
      "source": [
        "titanic_Y_col = titanic_train_df.columns[1]\n",
        "titanic_X_col = titanic_train_df.columns[2:]\n",
        "titanic_X_col = titanic_X_col.drop(['Name','Ticket'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyPiK5Cn9Zqn"
      },
      "outputs": [],
      "source": [
        "titanic_X, titanic_Y = titanic_train_df[titanic_X_col].copy(), titanic_train_df[titanic_Y_col].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJkd_rj99lsX"
      },
      "outputs": [],
      "source": [
        "numeric_cols = titanic_train_df[titanic_X_col].select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_cols = titanic_train_df[titanic_X_col].select_dtypes(exclude=np.number).columns.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_1TeKN79ryv"
      },
      "outputs": [],
      "source": [
        "# Impute and scale numeric columns\n",
        "imputer = SimpleImputer().fit(titanic_train_df[numeric_cols])\n",
        "titanic_X[numeric_cols] = imputer.transform(titanic_X[numeric_cols])\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler().fit(titanic_X[numeric_cols])\n",
        "titanic_X[numeric_cols] = scaler.transform(titanic_X[numeric_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5-fQpSv9yLI"
      },
      "outputs": [],
      "source": [
        "# One-hot encode categorical columns\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore').fit(titanic_X[categorical_cols])\n",
        "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
        "titanic_X[encoded_cols] = encoder.transform(titanic_X[categorical_cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "661JrU5T-owI"
      },
      "outputs": [],
      "source": [
        "titanic_X = titanic_X[numeric_cols + encoded_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9NEtRtI-t-A"
      },
      "outputs": [],
      "source": [
        "titanic_X_Train, titanic_X_Test, titanic_Y_Train, titanic_Y_Test = train_test_split(titanic_X, titanic_Y, test_size = 0.30,random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8pIPoNK-5dQ"
      },
      "outputs": [],
      "source": [
        "!pip install -U pymoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaFweg5d_Nai"
      },
      "outputs": [],
      "source": [
        "from pymoo.algorithms.moo.nsga3 import NSGA3\n",
        "from pymoo.factory import get_problem, get_reference_directions, get_sampling, get_crossover, get_mutation, get_termination\n",
        "from pymoo.operators.selection.rnd import RandomSelection\n",
        "from pymoo.operators.crossover.sbx import SBX\n",
        "from pymoo.operators.mutation.pm import PolynomialMutation\n",
        "from pymoo.termination.default import DefaultMultiObjectiveTermination\n",
        "from pymoo.core.problem import Problem\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.operators.sampling.lhs import LHS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNElZIJdAwqk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3Tw5cORA7yx"
      },
      "outputs": [],
      "source": [
        "def test_params(**params):\n",
        "    model = RandomForestClassifier(random_state=42, n_jobs=-1, **params).fit(titanic_X_Train, titanic_Y_Train)\n",
        "    train_accuracy_score = accuracy_score(titanic_Y_Train, model.predict(titanic_X_Train))\n",
        "    val_accuracy_score = accuracy_score(titanic_Y_Test, model.predict(titanic_X_Test))\n",
        "    return train_accuracy_score, val_accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_sqyoAA_Y1Z"
      },
      "outputs": [],
      "source": [
        "# define the hyperparameter optimization problem\n",
        "class HyperparameterOptimizationProblem(Problem):\n",
        "\n",
        "    def __init__(self,level):\n",
        "        # define the lower and upper bounds of the hyperparameters\n",
        "        # n_estimators: number of trees in the forest (integer)\n",
        "        # max_depth: maximum depth of each tree (integer)\n",
        "        # max_features: maximum number of features (integer)\n",
        "        # min_samples_leaf: minimum number of samples required to be at a leaf node (integer)\n",
        "        self.level = level\n",
        "        self.var_ranges = [\n",
        "            [(10, 500), (2, 8), (2,30), (1,5), (0, 0.3)],\n",
        "            [(10, 600), (2, 12), (2,40), (1,9), (0,0.5)]\n",
        "        ]\n",
        "        xl = np.array([10, 2, 2, 1, 0])\n",
        "        xu = np.array([600, 12, 40, 9, 0.5])\n",
        "\n",
        "        # initialize the problem with 4 variables and 2 objectives\n",
        "        super().__init__(n_var = 5, n_obj = 3,\n",
        "                         xl=[rng[0] for rng in self.var_ranges[level]],\n",
        "                         xu=[rng[1] for rng in self.var_ranges[level]]\n",
        "            )\n",
        "\n",
        "    def _evaluate(self, x, out, *args, **kwargs):\n",
        "        # evaluate each solution (each row of x)\n",
        "        f = np.zeros((x.shape[0], self.n_obj))\n",
        "        for i in range(x.shape[0]):\n",
        "            # get the hyperparameters\n",
        "            n_estimators = int(x[i, 0])\n",
        "            max_depth = int(x[i, 1])\n",
        "            min_samples_split = int(x[i, 2])\n",
        "            min_samples_leaf = int(x[i, 3])\n",
        "            min_weight_fraction_leaf = int(x[i, 4])\n",
        "\n",
        "\n",
        "            # build and train the random forest model\n",
        "            model = RandomForestClassifier(n_estimators=n_estimators,\n",
        "                                           max_depth=max_depth,\n",
        "                                           min_samples_split=min_samples_split,\n",
        "                                           min_samples_leaf = min_samples_leaf,\n",
        "                                           min_weight_fraction_leaf = min_weight_fraction_leaf,\n",
        "                                           max_features=\"sqrt\",\n",
        "                                           random_state=42,\n",
        "                                           n_jobs = -1)\n",
        "            model.fit(titanic_X_Train, titanic_Y_Train)\n",
        "\n",
        "            # predict on the test set\n",
        "            y_pred = model.predict(titanic_X_Test)\n",
        "\n",
        "            # calculate the accuracy, f1 and ROC/AUC score as the objectives\n",
        "            f[i, 0] = -accuracy_score(titanic_Y_Test, y_pred) # negate because we want to maximize\n",
        "            f[i, 1] = -f1_score(titanic_Y_Test, y_pred) # negate because we want to maximize\n",
        "            f[i, 2] = -roc_auc_score(titanic_Y_Test, y_pred) # negate because we want to maximize\n",
        "\n",
        "\n",
        "        # assign the objectives to the output dictionary\n",
        "        out[\"F\"] = f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UtYt5uI_3aE"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "# create an instance of the problem\n",
        "problem = HyperparameterOptimizationProblem(level=0)\n",
        "problem1 = HyperparameterOptimizationProblem(level=1)\n",
        "\n",
        "# create an instance of NSGA-III algorithm\n",
        "algorithm = NSGA3(\n",
        "    pop_size= 100,\n",
        "    ref_dirs=get_reference_directions(\"das-dennis\", 3, n_partitions=12),\n",
        "    # sampling=get_sampling(\"int_random\"),\n",
        "    sampling=LHS(),\n",
        "    selection = RandomSelection(),\n",
        "    # crossover=get_crossover(\"int_sbx\", prob=0.9, eta=15),\n",
        "    crossover = SBX(prob=0.6, prob_var=0.5),\n",
        "    mutation=PolynomialMutation(prob=0.5),\n",
        "    eliminate_duplicates=True)\n",
        "\n",
        "algorithm1 = NSGA3(\n",
        "    pop_size= 50,\n",
        "    ref_dirs=get_reference_directions(\"das-dennis\", 3, n_partitions=12),\n",
        "    # sampling=get_sampling(\"int_random\"),\n",
        "    sampling=LHS(),\n",
        "    selection = RandomSelection(),\n",
        "    # crossover=get_crossover(\"int_sbx\", prob=0.9, eta=15),\n",
        "    crossover = SBX(prob=0.9, prob_var=0.8),\n",
        "    mutation=PolynomialMutation(prob=0.8),\n",
        "    eliminate_duplicates=True)\n",
        "\n",
        "# create an instance of termination criterion\n",
        "# termination = get_termination(\"n_gen\", 50)\n",
        "\n",
        "# early stop\n",
        "termination = DefaultMultiObjectiveTermination(\n",
        "    xtol=1e-8,           # movement in the design space xtol\n",
        "    cvtol=1e-6,          # the convergence in the constraint cv_tol\n",
        "    ftol=0.0025,         # objective space f_tol.\n",
        "    period=30,\n",
        "    n_max_gen=50,        # maximum number of generations n_max_gen\n",
        "    n_max_evals=100000   # function evaluations n_max_evals\n",
        ")\n",
        "\n",
        "# perform the optimization\n",
        "res = minimize(problem,\n",
        "               algorithm,\n",
        "               termination,\n",
        "               seed=42,\n",
        "               save_history=True,\n",
        "               verbose=True)\n",
        "res1 = minimize(problem1,\n",
        "               algorithm1,\n",
        "               termination,\n",
        "               seed=42,\n",
        "               seed_population=res.pop,\n",
        "               save_history=True,\n",
        "               verbose=True)\n",
        "\n",
        "# print the results\n",
        "print(f\"Best solution found: \\nX = {res1.X.astype(int)} \\nF = {-res1.F}\") # negate F because we maximized\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlFRxFda7ICf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}